# üéØ SISTEMA AVAN√áADO DE TREINO - 30 MODELOS + OTIMIZA√á√ÉO

## Vis√£o Geral

Expandimos o sistema de 10 para **30 arquiteturas LSTM/GRU** com **otimiza√ß√£o inteligente de hiperpar√¢metros**.

---

## üèóÔ∏è Arquivos Criados

### 1. `app/ml/model_zoo_advanced.py`
**30 arquiteturas de alto desempenho** organizadas em 6 categorias:

#### Categoria 1: LSTM Base & Variants (1-5)
- **Modelo 1**: LSTM Classic (64/32)
- **Modelo 2**: LSTM + LayerNormalization
- **Modelo 3**: LSTM + BatchNormalization
- **Modelo 4**: LSTM Narrow-Deep (32¬≥)
- **Modelo 5**: LSTM Wide-Shallow (256)

#### Categoria 2: GRU Base & Variants (6-10)
- **Modelo 6**: GRU Classic (64/32)
- **Modelo 7**: GRU Deep (128/64/32)
- **Modelo 8**: GRU Wide (192/96)
- **Modelo 9**: GRU Residual Dense
- **Modelo 10**: GRU Hybrid (80/80/40)

#### Categoria 3: Bidirectional (11-15)
- **Modelo 11**: BiLSTM Classic (64/32)
- **Modelo 12**: BiGRU Classic (64/32)
- **Modelo 13**: BiLSTM Deep (96/64/32)
- **Modelo 14**: BiGRU Deep (96/64/32)
- **Modelo 15**: BiLSTM+BiGRU Mix

#### Categoria 4: Stacked Deep Networks (16-20)
- **Modelo 16**: Stacked LSTM (128‚Üí32)
- **Modelo 17**: Stacked GRU (128‚Üí32)
- **Modelo 18**: Pyramid LSTM (256‚Üí16)
- **Modelo 19**: Inverted Pyramid (32‚Üí128)
- **Modelo 20**: Diamond LSTM (64/128/128/64)

#### Categoria 5: Residual & Skip Connections (21-25)
- **Modelo 21**: LSTM Residual v1
- **Modelo 22**: LSTM Residual v2
- **Modelo 23**: Skip Connection Dense
- **Modelo 24**: Highway LSTM
- **Modelo 25**: DenseNet-style LSTM

#### Categoria 6: Attention & Hybrid (26-30)
- **Modelo 26**: Self-Attention LSTM
- **Modelo 27**: Multi-Head Attention
- **Modelo 28**: CNN+LSTM Hybrid
- **Modelo 29**: LSTM TimeDistributed
- **Modelo 30**: Ensemble Multi-Path

---

### 2. `app/ml/hyperparameter_optimizer.py`
**Sistema de otimiza√ß√£o com 3 estrat√©gias:**

#### A. Grid Search
- Testa **TODAS** as combina√ß√µes poss√≠veis
- **Pr√≥s**: Garante encontrar melhor combina√ß√£o
- **Contras**: MUITO lento (milhares de testes)
- **Quando usar**: Poucos modelos (1-5) e tempo dispon√≠vel

#### B. Random Search
- Testa **N amostras aleat√≥rias**
- **Pr√≥s**: R√°pido e eficiente
- **Contras**: Pode perder √≥timo global
- **Quando usar**: Padr√£o para 5-15 modelos

#### C. Bayesian Optimization
- **Aprende** com resultados anteriores
- Explora vizinhan√ßa dos melhores (70% exploitation)
- Adiciona explora√ß√£o aleat√≥ria (30% exploration)
- **Pr√≥s**: Mais inteligente, converge r√°pido
- **Contras**: Precisa de >5 amostras iniciais
- **Quando usar**: >15 modelos ou tempo limitado

**Espa√ßo de Busca:**
```python
'learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01]
'batch_size': [16, 32, 64, 128]
'dropout_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]
'epochs': [10, 20, 30, 50]
'activation': ['relu', 'tanh', 'elu', 'selu', 'swish', 'gelu', 'leaky_relu']
```

**Fun√ß√µes de Ativa√ß√£o (15 dispon√≠veis):**
- B√°sicas: relu, tanh, sigmoid, linear
- Avan√ßadas: leaky_relu, elu, selu
- Exponenciais: exponential, softplus, softsign
- Modernas: swish/SiLU, mish, gelu
- Hard variants: hard_sigmoid, hard_swish

**Early Stopping Inteligente:**
- Para se valida√ß√£o n√£o melhora por N epochs (patience=5)
- Detecta diverg√™ncia (loss aumentando)
- Evita overfitting

---

### 3. `app/ml/trainer_advanced.py`
**Dois modos de treino:**

#### MODO R√ÅPIDO (`train_all_models_fast_mode`)
- Testa 30 modelos com **1 epoch cada**
- Par√¢metros fixos (batch_size=32, learning_rate=0.001)
- **Tempo estimado**: ~5 minutos
- **Objetivo**: Identificar arquiteturas promissoras rapidamente
- ‚úÖ **Responde √† pergunta**: "O treino r√°pido testa todas as fun√ß√µes?"
  - **N√ÉO**, usa par√¢metros fixos (ativa√ß√£o padr√£o = relu)

#### MODO OTIMIZADO (`train_all_models_with_optimization`)
- Para CADA modelo, faz busca de hiperpar√¢metros
- Testa learning_rate, batch_size, dropout, activation, epochs
- **Tempo estimado**: 30-60 minutos (depende de n_trials e estrat√©gia)
- **Objetivo**: Encontrar melhor configura√ß√£o poss√≠vel
- Salva campe√£o no disco (.keras + .scaler + .json)
- Registra no banco de dados (ModelRegistry)
- ‚úÖ **Responde √† pergunta**: "O treino for√ßado faz depura√ß√£o e altera par√¢metros?"
  - **SIM**, testa m√∫ltiplas combina√ß√µes e busca melhor cen√°rio

**Callbacks Avan√ßados:**
- `EarlyStopping`: para se val_loss n√£o melhora
- `ReduceLROnPlateau`: reduz learning rate em 50% se estagnado

---

### 4. `app/routes/api.py` (Novas Rotas)

#### POST `/api/train-advanced`
**Body JSON:**
```json
{
  "mode": "fast",  // ou "optimized"
  "model_ids": [1, 2, 3],  // null = todos 30
  "optimization_strategy": "random",  // grid/random/bayesian
  "n_trials": 20,  // tentativas por modelo
  "lookback": 60,
  "horizon": 1
}
```

**Resposta (modo fast):**
```json
{
  "status": "success",
  "mode": "fast",
  "winner": {
    "model_id": 11,
    "model_name": "BiLSTM Classic (64/32)",
    "rmse": 0.0234
  },
  "total_models": 30,
  "results": [...]
}
```

**Resposta (modo optimized):**
```json
{
  "status": "success",
  "mode": "optimized",
  "winner": {
    "model_id": 26,
    "model_name": "Self-Attention LSTM",
    "best_rmse": 0.0187,
    "best_params": {
      "learning_rate": 0.001,
      "batch_size": 64,
      "dropout_rate": 0.2,
      "epochs": 30,
      "activation": "swish"
    },
    "n_trials": 20,
    "elapsed_time": 342.5
  },
  "total_models_tested": 30,
  "total_time": 1823.4,
  "avg_time_per_model": 60.8,
  "optimization_strategy": "bayesian",
  "all_results": [...]
}
```

#### GET `/api/models-info`
Retorna lista dos 30 modelos organizados por categoria.

---

### 5. `app/templates/advanced_training.html`
**Interface gr√°fica moderna com:**
- Sele√ß√£o de modo (R√°pido vs Otimizado)
- Configura√ß√£o de estrat√©gia (Grid/Random/Bayesian)
- N√∫mero de tentativas por modelo
- Lookback e Horizon
- Barra de progresso animada
- Card do campe√£o com m√©tricas
- Tabela com ranking de todos os modelos
- Medals (ü•áü•àü•â) para top-3

---

## üöÄ Como Usar

### 1. Acessar a Interface
```
http://localhost:5000/advanced-training
```

### 2. Modo R√°pido (Explora√ß√£o)
1. Selecione "Modo R√°pido"
2. Ajuste lookback/horizon se necess√°rio
3. Clique "Iniciar Treino Avan√ßado"
4. Aguarde ~5 minutos
5. Veja qual arquitetura teve melhor RMSE

### 3. Modo Otimizado (Produ√ß√£o)
1. Selecione "Modo Otimizado"
2. Escolha estrat√©gia:
   - **Random Search** (recomendado): r√°pido e eficiente
   - **Bayesian**: mais inteligente, converge melhor
   - **Grid Search**: completo mas lento
3. Configure tentativas (20 = bom equil√≠brio)
4. Clique "Iniciar Treino Avan√ßado"
5. Aguarde 30-60 minutos
6. Modelo campe√£o salvo automaticamente em `models/`

### 4. Via API (Python)
```python
import requests

# Modo r√°pido
response = requests.post('http://localhost:5000/api/train-advanced', json={
    "mode": "fast",
    "lookback": 60,
    "horizon": 1
})
print(response.json())

# Modo otimizado
response = requests.post('http://localhost:5000/api/train-advanced', json={
    "mode": "optimized",
    "optimization_strategy": "bayesian",
    "n_trials": 30,
    "model_ids": [1, 11, 21, 26, 30],  # testar apenas 5 modelos espec√≠ficos
    "lookback": 60,
    "horizon": 1
})
print(response.json())
```

---

## üìä Compara√ß√£o de Estrat√©gias

| Estrat√©gia | Velocidade | Qualidade | Uso de Mem√≥ria | Recomendado Para |
|-----------|-----------|-----------|----------------|------------------|
| Grid Search | ‚≠ê (lento) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (alto) | Poucos modelos, tempo ilimitado |
| Random Search | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê (baixo) | **Uso geral (padr√£o)** |
| Bayesian | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê (m√©dio) | Muitos modelos, produ√ß√£o |

---

## üéØ Respostas √†s Perguntas

### "O treino r√°pido testa todas as fun√ß√µes?"
**N√ÉO**. O modo r√°pido (`fast`) testa apenas as **30 arquiteturas** com par√¢metros fixos:
- 1 epoch
- batch_size=32
- learning_rate=0.001 (Adam)
- dropout_rate=0.2
- activation=relu (padr√£o de cada layer)

**Objetivo**: Identificar qual **arquitetura** (LSTM, GRU, BiLSTM, Attention, etc.) √© mais promissora.

---

### "O treino for√ßado (optimized) faz depura√ß√£o e altera par√¢metros?"
**SIM**! O modo otimizado faz **busca inteligente**:

1. **Para CADA modelo** (1-30):
   - Testa N combina√ß√µes de hiperpar√¢metros (n_trials=20 padr√£o)
   - Varia: learning_rate, batch_size, dropout, epochs, activation
   - Total de combina√ß√µes poss√≠veis: 5 √ó 4 √ó 6 √ó 4 √ó 7 = **3.360 combina√ß√µes**

2. **Estrat√©gia de busca** (Random/Bayesian):
   - N√£o testa todas 3.360 (seria semanas)
   - Random: testa 20 aleat√≥rias por modelo
   - Bayesian: aprende com resultados e foca em regi√µes promissoras

3. **Para cada tentativa**:
   - Treina modelo com par√¢metros espec√≠ficos
   - Avalia RMSE em valida√ß√£o
   - Early stopping se n√£o melhorar

4. **Resultado**:
   - Melhor configura√ß√£o por modelo
   - Campe√£o global entre todos os modelos
   - **Salva automaticamente** o vencedor

**Exemplo de resultado:**
```
Modelo 26 (Self-Attention LSTM):
  - Testou 20 combina√ß√µes
  - Melhor: learning_rate=0.001, batch_size=64, dropout=0.2, activation=swish, epochs=30
  - RMSE: 0.0187
  
CAMPE√ÉO GLOBAL: Modelo 26
```

---

## üé® Funcionalidades de Ativa√ß√£o

Cada modelo pode usar **15 fun√ß√µes de ativa√ß√£o diferentes**:

### B√°sicas
- `relu`: Rectified Linear Unit (padr√£o)
- `tanh`: Tangente Hiperb√≥lica (padr√£o LSTM)
- `sigmoid`: Sigmoid (0 a 1)
- `linear`: Sem ativa√ß√£o

### Avan√ßadas (Leaky fam√≠lia)
- `leaky_relu`: Permite pequeno gradiente negativo
- `elu`: Exponential Linear Unit
- `selu`: Scaled ELU (auto-normalizante)

### Exponenciais
- `exponential`: Crescimento exponencial
- `softplus`: Suave vers√£o de ReLU
- `softsign`: Vers√£o suave de tanh

### Modernas (State-of-the-art)
- `swish`: x * sigmoid(x) - usado em EfficientNet
- `mish`: x * tanh(softplus(x)) - melhor que ReLU
- `gelu`: Gaussian Error Linear Unit - usado em BERT/GPT

### Hard Variants
- `hard_sigmoid`: Vers√£o r√°pida de sigmoid
- `hard_swish`: Vers√£o r√°pida de swish

**Otimiza√ß√£o autom√°tica testa essas ativa√ß√µes** e escolhe a melhor para cada modelo!

---

## üîß Pr√≥ximos Passos

1. **Testar sistema**:
   ```bash
   # Acessar interface
   http://localhost:5000/advanced-training
   
   # Modo r√°pido primeiro (5 min)
   # Ver qual categoria de modelos funciona melhor
   
   # Depois modo otimizado (30-60 min)
   # Deixar rodando overnight para melhor resultado
   ```

2. **Monitorar progresso**:
   - Logs em tempo real no terminal
   - Barra de progresso na interface
   - M√©tricas Prometheus em `/metrics`

3. **Analisar resultados**:
   - Ranking completo de todos os modelos
   - Hiperpar√¢metros do campe√£o
   - Tempo de treino por modelo

4. **Usar campe√£o**:
   - Automaticamente salvo em `models/NVDA_{model_id}_{timestamp}.keras`
   - J√° pode usar em `/custom-model` para predi√ß√µes
   - Registrado no banco como `is_winner=True`

---

## üìà Performance Esperada

### Modo R√°pido
- **Tempo**: ~5 minutos (30 modelos √ó 1 epoch)
- **Uso de RAM**: ~2-4 GB
- **CPU**: 50-70%
- **Resultado**: Top-3 arquiteturas promissoras

### Modo Otimizado (n_trials=20)
- **Tempo**: ~30-60 minutos (30 modelos √ó 20 trials = 600 treinos)
- **Uso de RAM**: ~4-8 GB (com early stopping)
- **CPU**: 70-90%
- **Resultado**: Modelo otimizado pronto para produ√ß√£o

### Modo Otimizado (n_trials=50)
- **Tempo**: ~2-3 horas (30 modelos √ó 50 trials = 1500 treinos)
- **Resultado**: Melhor modelo poss√≠vel

---

## ‚úÖ Sistema Completo

‚úÖ **30 arquiteturas** (LSTM, GRU, BiLSTM, BiGRU, Residual, Attention, Hybrid)
‚úÖ **15 fun√ß√µes de ativa√ß√£o** (relu, tanh, swish, gelu, mish, etc.)
‚úÖ **3 estrat√©gias de otimiza√ß√£o** (Grid, Random, Bayesian)
‚úÖ **5 hiperpar√¢metros otimizados** (lr, batch, dropout, epochs, activation)
‚úÖ **Early stopping** inteligente
‚úÖ **Interface gr√°fica** moderna
‚úÖ **API REST** completa
‚úÖ **Salvamento autom√°tico** do campe√£o
‚úÖ **Registro no banco** de dados

**Sistema pronto para encontrar o melhor modelo LSTM para NVIDIA!**
